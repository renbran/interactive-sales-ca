# Ollama Configuration for Scholarix Interactive Sales CA
# Copy this file to .env.local and update with your Ollama server details

# Ollama server URL (default: http://localhost:11434)
VITE_OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use (recommended: llama3.1:8b, llama3.2:3b, or mistral:7b)
VITE_OLLAMA_MODEL=llama3.1:8b

# Optional: If you're using a remote Ollama server
# VITE_OLLAMA_BASE_URL=https://your-ollama-server.com

# For production deployment on Cloudflare Pages:
# 1. Set up Ollama on a server accessible from the internet
# 2. Update VITE_OLLAMA_BASE_URL to point to your server
# 3. Ensure CORS is properly configured on your Ollama server
# 4. Consider using authentication if needed